{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ°Ô∏è Network Intrusion Detection System (NIDS)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook documents the development of a **Machine Learning-based Network Intrusion Detection System** that analyzes network traffic and identifies malicious activities with **95% F1-score accuracy**.\n",
    "\n",
    "### What We'll Build:\n",
    "1. **Data Loading & Exploration** - Understanding the CICIDS2017 dataset\n",
    "2. **Feature Engineering** - Preprocessing, scaling, and handling class imbalance\n",
    "3. **Model Training** - Random Forest classifier for attack detection\n",
    "4. **Model Evaluation** - Performance metrics and feature importance\n",
    "5. **Interactive Dashboard** - Real-time visualization with Streamlit\n",
    "\n",
    "### Technologies Used:\n",
    "- **Python 3.8+**\n",
    "- **Scikit-learn** - Machine Learning\n",
    "- **Pandas & NumPy** - Data manipulation\n",
    "- **Matplotlib & Plotly** - Visualization\n",
    "- **Streamlit** - Interactive dashboard\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# For handling class imbalance\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 2. Data Loading\n",
    "\n",
    "We're using the **CICIDS2017: Cleaned & Preprocessed** dataset from Kaggle.\n",
    "\n",
    "**Dataset Info:**\n",
    "- Source: Canadian Institute for Cybersecurity\n",
    "- Contains labeled network traffic (benign + attacks)\n",
    "- Pre-cleaned version with 2.5M+ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "DATA_FILE = \"data/cicids2017_cleaned.csv\"\n",
    "\n",
    "print(\"üìÇ Loading dataset...\")\n",
    "df = pd.read_csv(DATA_FILE, low_memory=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"   Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"üìã First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(f\"   Total Samples: {len(df):,}\")\n",
    "print(f\"   Total Features: {len(df.columns) - 1}\")  # Excluding label\n",
    "print(f\"   Label Column: 'Attack Type'\")\n",
    "print(f\"\\n   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"\\n   Missing Values: {df.isnull().sum().sum()}\")\n",
    "print(f\"   Duplicate Rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names\n",
    "print(\"üìù All Columns:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"   {i:2}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack type distribution\n",
    "print(\"üéØ Attack Type Distribution:\")\n",
    "attack_counts = df['Attack Type'].value_counts()\n",
    "attack_percentages = (attack_counts / len(df) * 100).round(2)\n",
    "\n",
    "distribution = pd.DataFrame({\n",
    "    'Attack Type': attack_counts.index,\n",
    "    'Count': attack_counts.values,\n",
    "    'Percentage (%)': attack_percentages.values\n",
    "})\n",
    "print(distribution.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attack distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#00C851', '#ff4444', '#CC0000', '#ffbb33', '#ff8800', '#aa66cc', '#0099CC']\n",
    "axes[0].pie(attack_counts.values, labels=attack_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors, explode=[0.05]*len(attack_counts))\n",
    "axes[0].set_title('Attack Type Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "bars = axes[1].bar(attack_counts.index, attack_counts.values, color=colors)\n",
    "axes[1].set_xlabel('Attack Type', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Attack Type Counts', fontsize=14, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, attack_counts.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000, \n",
    "                 f'{count:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('attack_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Class Imbalance Detected!\")\n",
    "print(f\"   Normal Traffic represents {attack_percentages['Normal Traffic']:.1f}% of data\")\n",
    "print(\"   We'll need to handle this in preprocessing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numeric features\n",
    "print(\"üìà Statistical Summary (first 10 features):\")\n",
    "df.describe().iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for top features\n",
    "# Select numeric columns only\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns[:15]  # First 15 for visibility\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap (Top 15 Features)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 4. Data Preprocessing & Feature Engineering\n",
    "\n",
    "Steps:\n",
    "1. Clean data (remove duplicates, handle missing/infinite values)\n",
    "2. Encode labels (text ‚Üí numbers)\n",
    "3. Split into training and testing sets\n",
    "4. Scale features using StandardScaler\n",
    "5. Handle class imbalance using undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For faster execution, we'll use a sample of the data\n",
    "# You can set SAMPLE_SIZE = None to use the full dataset\n",
    "SAMPLE_SIZE = 200000  # 200K samples for demonstration\n",
    "\n",
    "if SAMPLE_SIZE:\n",
    "    print(f\"üìä Using sample of {SAMPLE_SIZE:,} rows for faster training...\")\n",
    "    df_sample = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "else:\n",
    "    print(\"üìä Using full dataset...\")\n",
    "    df_sample = df.copy()\n",
    "\n",
    "print(f\"   Working with: {len(df_sample):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Cleaning\n",
    "print(\"üßπ Step 1: Data Cleaning\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Remove duplicates\n",
    "initial_rows = len(df_sample)\n",
    "df_clean = df_sample.drop_duplicates()\n",
    "print(f\"   Removed {initial_rows - len(df_clean):,} duplicate rows\")\n",
    "\n",
    "# Check for infinite values\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "inf_count = np.isinf(df_clean[numeric_cols]).sum().sum()\n",
    "print(f\"   Infinite values found: {inf_count}\")\n",
    "\n",
    "# Check for NaN values\n",
    "nan_count = df_clean.isna().sum().sum()\n",
    "print(f\"   NaN values found: {nan_count}\")\n",
    "\n",
    "print(f\"\\n   ‚úÖ Clean data: {len(df_clean):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Label Encoding\n",
    "print(\"üè∑Ô∏è  Step 2: Label Encoding\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "LABEL_COLUMN = \"Attack Type\"\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_clean['Label_Encoded'] = label_encoder.fit_transform(df_clean[LABEL_COLUMN])\n",
    "\n",
    "# Create label mapping\n",
    "label_mapping = dict(zip(\n",
    "    label_encoder.transform(label_encoder.classes_),\n",
    "    label_encoder.classes_\n",
    "))\n",
    "\n",
    "print(\"   Label Mapping:\")\n",
    "for code, name in sorted(label_mapping.items()):\n",
    "    count = (df_clean['Label_Encoded'] == code).sum()\n",
    "    print(f\"      {code} ‚Üí {name} ({count:,} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare Features (X) and Target (y)\n",
    "print(\"üì¶ Step 3: Preparing Features\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Exclude label columns from features\n",
    "exclude_cols = [LABEL_COLUMN, 'Label_Encoded']\n",
    "feature_cols = [col for col in df_clean.columns if col not in exclude_cols]\n",
    "\n",
    "X = df_clean[feature_cols].copy()\n",
    "y = df_clean['Label_Encoded'].copy()\n",
    "\n",
    "print(f\"   Features (X): {X.shape}\")\n",
    "print(f\"   Target (y): {y.shape}\")\n",
    "print(f\"   Feature columns: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train/Test Split\n",
    "print(\"‚úÇÔ∏è  Step 4: Train/Test Split\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Maintain class proportions\n",
    ")\n",
    "\n",
    "print(f\"   Training set: {len(X_train):,} samples ({100-TEST_SIZE*100:.0f}%)\")\n",
    "print(f\"   Testing set: {len(X_test):,} samples ({TEST_SIZE*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature Scaling\n",
    "print(\"‚öñÔ∏è  Step 5: Feature Scaling\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data ONLY, then transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"   Scaler fitted on training data\")\n",
    "print(f\"   Training data scaled: {X_train_scaled.shape}\")\n",
    "print(f\"   Testing data scaled: {X_test_scaled.shape}\")\n",
    "print(f\"\\n   Feature means after scaling: {X_train_scaled.mean():.6f} (should be ~0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Handle Class Imbalance\n",
    "print(\"üéØ Step 6: Handling Class Imbalance\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"   Before resampling:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"      Class {label} ({label_mapping[label]}): {count:,}\")\n",
    "\n",
    "# Apply undersampling\n",
    "undersampler = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "X_train_balanced, y_train_balanced = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n   After resampling:\")\n",
    "unique, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"      Class {label} ({label_mapping[label]}): {count:,}\")\n",
    "\n",
    "print(f\"\\n   Total: {len(y_train):,} ‚Üí {len(y_train_balanced):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 5. Model Training\n",
    "\n",
    "We'll use **Random Forest Classifier** because:\n",
    "- Excellent for tabular data with many features\n",
    "- Handles non-linear relationships well\n",
    "- Provides feature importance rankings\n",
    "- Resistant to overfitting\n",
    "- Fast training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "print(\"üå≤ Training Random Forest Classifier\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Model parameters\n",
    "N_ESTIMATORS = 100  # Number of trees\n",
    "MAX_DEPTH = None    # No limit on tree depth\n",
    "N_JOBS = -1         # Use all CPU cores\n",
    "\n",
    "print(f\"   Parameters:\")\n",
    "print(f\"      - n_estimators: {N_ESTIMATORS}\")\n",
    "print(f\"      - max_depth: {MAX_DEPTH}\")\n",
    "print(f\"      - n_jobs: {N_JOBS}\")\n",
    "print(f\"   Training data: {X_train_balanced.shape[0]:,} samples\")\n",
    "\n",
    "# Create and train model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=N_JOBS,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "print(\"\\n   Training in progress...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"   ‚úÖ Training complete in {training_time:.2f} seconds\")\n",
    "\n",
    "# Training accuracy\n",
    "train_accuracy = model.score(X_train_balanced, y_train_balanced)\n",
    "print(f\"   Training accuracy: {train_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "print(\"üìä Model Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\nüìà OVERALL METRICS:\")\n",
    "print(f\"   Accuracy:  {accuracy * 100:.2f}%\")\n",
    "print(f\"   Precision: {precision * 100:.2f}%\")\n",
    "print(f\"   Recall:    {recall * 100:.2f}%\")\n",
    "print(f\"   F1-Score:  {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nüìã CLASSIFICATION REPORT:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class_names = [label_mapping[i] for i in sorted(label_mapping.keys())]\n",
    "report = classification_report(y_test, y_pred, target_names=class_names, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "print(\"üéØ Confusion Matrix:\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.title('Confusion Matrix - Attack Classification', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class performance visualization\n",
    "print(\"üìä Per-Class Performance:\")\n",
    "\n",
    "# Calculate per-class metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_per_class, recall_per_class, f1_per_class, support = precision_recall_fscore_support(\n",
    "    y_test, y_pred, zero_division=0\n",
    ")\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Attack Type': class_names,\n",
    "    'Precision': precision_per_class,\n",
    "    'Recall': recall_per_class,\n",
    "    'F1-Score': f1_per_class,\n",
    "    'Support': support\n",
    "})\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, metrics_df['Precision'], width, label='Precision', color='#3498db')\n",
    "bars2 = ax.bar(x, metrics_df['Recall'], width, label='Recall', color='#e74c3c')\n",
    "bars3 = ax.bar(x + width, metrics_df['F1-Score'], width, label='F1-Score', color='#2ecc71')\n",
    "\n",
    "ax.set_xlabel('Attack Type', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Per-Class Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_performance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 7. Feature Importance Analysis\n",
    "\n",
    "Understanding which features are most important for detecting attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "print(\"üîç Feature Importance Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(feature_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "top_15 = feature_importance.head(15).sort_values('Importance', ascending=True)\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_15)))\n",
    "plt.barh(top_15['Feature'], top_15['Importance'], color=colors)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Most Important Features for Attack Detection', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 8. Save Model and Preprocessing Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "MODELS_DIR = \"models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"üíæ Saving Model and Preprocessing Objects\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(MODELS_DIR, 'random_forest_model.joblib')\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"   ‚úÖ Model saved: {model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = os.path.join(MODELS_DIR, 'scaler.joblib')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"   ‚úÖ Scaler saved: {scaler_path}\")\n",
    "\n",
    "# Save label encoder\n",
    "encoder_path = os.path.join(MODELS_DIR, 'label_encoder.joblib')\n",
    "joblib.dump(label_encoder, encoder_path)\n",
    "print(f\"   ‚úÖ Label encoder saved: {encoder_path}\")\n",
    "\n",
    "# Save label mapping\n",
    "mapping_path = os.path.join(MODELS_DIR, 'label_mapping.joblib')\n",
    "joblib.dump(label_mapping, mapping_path)\n",
    "print(f\"   ‚úÖ Label mapping saved: {mapping_path}\")\n",
    "\n",
    "# Save feature names\n",
    "features_path = os.path.join(MODELS_DIR, 'feature_names.joblib')\n",
    "joblib.dump(feature_cols, features_path)\n",
    "print(f\"   ‚úÖ Feature names saved: {features_path}\")\n",
    "\n",
    "# Display file sizes\n",
    "print(\"\\nüìÅ Saved Files:\")\n",
    "for filename in os.listdir(MODELS_DIR):\n",
    "    filepath = os.path.join(MODELS_DIR, filename)\n",
    "    size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "    print(f\"   - {filename}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 9. Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make prediction on a single sample\n",
    "print(\"üéØ Example Prediction\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get a random sample from test set\n",
    "sample_idx = np.random.randint(0, len(X_test))\n",
    "sample = X_test_scaled[sample_idx].reshape(1, -1)\n",
    "actual_label = y_test.iloc[sample_idx]\n",
    "\n",
    "# Predict\n",
    "predicted_label = model.predict(sample)[0]\n",
    "probabilities = model.predict_proba(sample)[0]\n",
    "\n",
    "print(f\"\\n   Actual: {label_mapping[actual_label]}\")\n",
    "print(f\"   Predicted: {label_mapping[predicted_label]}\")\n",
    "print(f\"   Confidence: {probabilities[predicted_label] * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n   All Probabilities:\")\n",
    "for i, prob in enumerate(probabilities):\n",
    "    print(f\"      {label_mapping[i]}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 10. Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üèÜ PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìä Dataset:\")\n",
    "print(f\"   - Source: CICIDS2017 (Cleaned & Preprocessed)\")\n",
    "print(f\"   - Total Samples: {len(df):,}\")\n",
    "print(f\"   - Features: {len(feature_cols)}\")\n",
    "print(f\"   - Classes: {len(label_mapping)} attack types\")\n",
    "\n",
    "print(\"\\nü§ñ Model:\")\n",
    "print(f\"   - Algorithm: Random Forest Classifier\")\n",
    "print(f\"   - Trees: {N_ESTIMATORS}\")\n",
    "print(f\"   - Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nüìà Performance:\")\n",
    "print(f\"   - Accuracy:  {accuracy * 100:.2f}%\")\n",
    "print(f\"   - Precision: {precision * 100:.2f}%\")\n",
    "print(f\"   - Recall:    {recall * 100:.2f}%\")\n",
    "print(f\"   - F1-Score:  {f1 * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nüîù Top 5 Most Important Features:\")\n",
    "for i, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"   {feature_importance.index.get_loc(i)+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Project Complete!\")\n",
    "print(\"   Run 'streamlit run dashboard/app.py' to launch the interactive dashboard.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
